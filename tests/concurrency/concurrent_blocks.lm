print("=== Concurrent Block Tests ===");

// ==========================================
//  Basic concurrent execution (batch mode)
// ==========================================
// concurrent = I/O-bound, default mode=batch
var shared_counter: atomic = 0;  // atomic for primitives, locked for objects

concurrent(ch=counts, mode=batch, cores=Auto, on_error=Stop,
           timeout=20s, grace=500ms, on_timeout=partial) {
    task(i in 1..3) {
        print("Concurrent task {i} running");
        sleep(randint(1, 3));
        shared_counter += 1;  // atomic add
        counts.send(shared_counter);
    }
} // auto-close counts when done or timeout+grace reached

iter (count in counts) {
    print("Updated counter: {count}");
}
print("Concurrent block finished");


// ==========================================
//  Async/await pattern (batch mode)
// ==========================================
concurrent(ch=results, mode=batch, cores=Auto, on_error=Auto,
           timeout=20s, grace=500ms, on_timeout=partial) {
    task() {
        var data = await fetchData();
        results.send(data);
    }
} // auto-close results

iter (result in results) {
    print("Got async result: {result}");
}


// ==========================================
//  Stream processing (I/O bound)
// ==========================================
concurrent(events: StreamEvent, ch=stream_out, mode=stream, cores=Auto,
           on_error=Stop, timeout=15s, grace=500ms, on_timeout=partial) {
    worker(event) {
        print("Processing event: {event}");
        stream_out.send("Handled {event.id}");
    }
} // auto-close stream_out

iter (msg in stream_out) {
    print("Result: {msg}");
}


// ==========================================
//  Async stream pipeline (I/O bound)
// ==========================================
concurrent(events: StreamEvent, ch=async_out, mode=async, timeout=20s, grace=500ms,
           on_timeout=partial, on_error=Stop) {
    worker(event) {
        var data = await fetchData(event.id);
        async_out.send("Processed {event.id} -> {data}");
    }
} // auto-close async_out

iter (msg in async_out) {
    print("Result: {msg}");
}


// Test parallel blocks 
print("=== Parallel Block Tests ===");

// ==========================================
//  Batch parallel block (CPU bound)
// ==========================================
parallel(ch=messages, mode=batch, cores=Auto, on_error=Auto,
         timeout=20s, grace=500ms, on_timeout=partial) {
    task(i in 1..3) {
        print("Task {i} running");
        sleep(randint(1, 3));
        messages.send("Task {i} done");
    }
} // auto-close messages

iter (message in messages) {
    print("Received: {message}");
}

// ==========================================
//  Stream processing (CPU bound, retries)
// ==========================================
parallel(events: FileChunks, ch=files_out, mode=stream, cores=Auto,
         on_error=Retry, timeout=60s,
         grace=500ms, on_timeout=partial) {
    worker(chunk) {
        process_chunk(chunk);
        files_out.send("Chunk {chunk.id} processed");
    }
} // auto-close files_out

iter (msg in files_out) {
    print(msg);
}

// ==========================================
//  Concurrent block with no parameters
// ==========================================
concurrent {
    task(i in 1..2) {
        print("Task {i} with default parameters");
    }
}

// ==========================================
//  Parallel block with invalid parameter
// ==========================================
// This should be handled gracefully by the parser
parallel(invalid_param="test") {
    task(i in 1..2) {
        print("This should not be executed");
    }
}
